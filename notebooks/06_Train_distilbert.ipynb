{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14298809,"sourceType":"datasetVersion","datasetId":9127545}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y protobuf\n!pip install protobuf==3.20.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:15:06.151675Z","iopub.execute_input":"2025-12-30T04:15:06.151997Z","iopub.status.idle":"2025-12-30T04:15:20.337766Z","shell.execute_reply.started":"2025-12-30T04:15:06.151966Z","shell.execute_reply":"2025-12-30T04:15:20.337022Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: protobuf 3.20.3\nUninstalling protobuf-3.20.3:\n  Successfully uninstalled protobuf-3.20.3\nCollecting protobuf==3.20.3\n  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nUsing cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\nInstalling collected packages: protobuf\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngrain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.20.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nray 2.52.1 requires click!=8.3.*,>=7.0, but you have click 8.3.1 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:15:20.339280Z","iopub.execute_input":"2025-12-30T04:15:20.339586Z","iopub.status.idle":"2025-12-30T04:15:20.343749Z","shell.execute_reply.started":"2025-12-30T04:15:20.339557Z","shell.execute_reply":"2025-12-30T04:15:20.343188Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# =========================\n# Imports\n# =========================\nimport json\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom transformers import (\n    DistilBertTokenizerFast,\n    DistilBertForTokenClassification,\n    get_linear_schedule_with_warmup\n)\nfrom pathlib import Path\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:15:30.466929Z","iopub.execute_input":"2025-12-30T04:15:30.467232Z","iopub.status.idle":"2025-12-30T04:15:39.648260Z","shell.execute_reply.started":"2025-12-30T04:15:30.467195Z","shell.execute_reply":"2025-12-30T04:15:39.647455Z"}},"outputs":[{"name":"stderr","text":"2025-12-30 04:15:36.082454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767068136.105442     303 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767068136.112746     303 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767068136.130296     303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767068136.130319     303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767068136.130321     303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767068136.130324     303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# =========================\n# Paths (Kaggle-safe)\n# =========================\nDATA_PATH = \"/kaggle/input/mindlens-data/span_ner.jsonl\"\nLABELS_PATH = \"/kaggle/input/mindlens-data/labels.json\"\nCLASS_WEIGHTS_PATH = \"/kaggle/input/mindlens-data/class_weights.pt\"\n\nCHECKPOINT_DIR = \"/kaggle/working/checkpoints\"\nPath(CHECKPOINT_DIR).mkdir(parents=True, exist_ok=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:15:52.279353Z","iopub.execute_input":"2025-12-30T04:15:52.280017Z","iopub.status.idle":"2025-12-30T04:15:52.284712Z","shell.execute_reply.started":"2025-12-30T04:15:52.279984Z","shell.execute_reply":"2025-12-30T04:15:52.283921Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# =========================\n# Device\n# =========================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:15:54.430635Z","iopub.execute_input":"2025-12-30T04:15:54.431198Z","iopub.status.idle":"2025-12-30T04:15:54.435456Z","shell.execute_reply.started":"2025-12-30T04:15:54.431170Z","shell.execute_reply":"2025-12-30T04:15:54.434737Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from transformers import DistilBertTokenizerFast\n\ntokenizer = DistilBertTokenizerFast.from_pretrained(\n    \"distilbert-base-uncased\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:15:57.604073Z","iopub.execute_input":"2025-12-30T04:15:57.604366Z","iopub.status.idle":"2025-12-30T04:15:58.005236Z","shell.execute_reply.started":"2025-12-30T04:15:57.604338Z","shell.execute_reply":"2025-12-30T04:15:58.004660Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# =========================\n# Load label maps\n# =========================\nwith open(LABELS_PATH) as f:\n    label2id = json.load(f)\n\nid2label = {v: k for k, v in label2id.items()}\nnum_labels = len(label2id)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:15:59.345987Z","iopub.execute_input":"2025-12-30T04:15:59.346647Z","iopub.status.idle":"2025-12-30T04:15:59.361941Z","shell.execute_reply.started":"2025-12-30T04:15:59.346614Z","shell.execute_reply":"2025-12-30T04:15:59.361386Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def collate_fn(batch):\n    input_ids = [item[\"input_ids\"] for item in batch]\n    attention_masks = [item[\"attention_mask\"] for item in batch]\n    labels = [item[\"labels\"] for item in batch]\n\n    input_ids = torch.nn.utils.rnn.pad_sequence(\n        input_ids,\n        batch_first=True,\n        padding_value=tokenizer.pad_token_id\n    )\n\n    attention_masks = torch.nn.utils.rnn.pad_sequence(\n        attention_masks,\n        batch_first=True,\n        padding_value=0\n    )\n\n    labels = torch.nn.utils.rnn.pad_sequence(\n        labels,\n        batch_first=True,\n        padding_value=-100   # VERY IMPORTANT\n    )\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_masks,\n        \"labels\": labels\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:16:01.587971Z","iopub.execute_input":"2025-12-30T04:16:01.588640Z","iopub.status.idle":"2025-12-30T04:16:01.593747Z","shell.execute_reply.started":"2025-12-30T04:16:01.588608Z","shell.execute_reply":"2025-12-30T04:16:01.592998Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# =========================\n# Load class weights\n# =========================\nckpt = torch.load(CLASS_WEIGHTS_PATH, map_location=\"cpu\")\nclass_weights = ckpt[\"class_weights\"].to(device)\n\n# =========================\n# Dataset\n# =========================\nclass SpanNERDataset(Dataset):\n    def __init__(self, data_or_path):\n        if isinstance(data_or_path, str):\n            # original behavior (path-based)\n            self.samples = []\n            with open(data_or_path) as f:\n                for line in f:\n                    self.samples.append(json.loads(line))\n        else:\n            # new behavior (list-based)\n            self.samples = data_or_path\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        s = self.samples[idx]\n        return {\n            \"input_ids\": torch.tensor(s[\"input_ids\"], dtype=torch.long),\n            \"attention_mask\": torch.tensor(s[\"attention_mask\"], dtype=torch.long),\n            \"labels\": torch.tensor(s[\"labels\"], dtype=torch.long),\n        }","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:16:04.182372Z","iopub.execute_input":"2025-12-30T04:16:04.182963Z","iopub.status.idle":"2025-12-30T04:16:04.283283Z","shell.execute_reply.started":"2025-12-30T04:16:04.182933Z","shell.execute_reply":"2025-12-30T04:16:04.282696Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import random\n\nwith open(DATA_PATH) as f:\n    all_samples = [json.loads(line) for line in f]\n\nrandom.seed(42)\nrandom.shuffle(all_samples)\n\nsplit = int(0.9 * len(all_samples))\ntrain_samples = all_samples[:split]\nval_samples   = all_samples[split:]\n\n# =========================\n# DataLoader\n# =========================\ntrain_dataset = SpanNERDataset(train_samples)\nval_dataset   = SpanNERDataset(val_samples)\n\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=8,\n    shuffle=True,\n    collate_fn=collate_fn\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=8,\n    shuffle=False,   # IMPORTANT\n    collate_fn=collate_fn\n)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:16:07.037388Z","iopub.execute_input":"2025-12-30T04:16:07.037722Z","iopub.status.idle":"2025-12-30T04:16:07.106110Z","shell.execute_reply.started":"2025-12-30T04:16:07.037693Z","shell.execute_reply":"2025-12-30T04:16:07.105475Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# =========================\n# Model\n# =========================\nmodel = DistilBertForTokenClassification.from_pretrained(\n    \"distilbert-base-uncased\",\n    num_labels=num_labels,\n    id2label=id2label,\n    label2id=label2id\n)\nmodel.to(device)\n\n# =========================\n# Loss, Optimizer, Scheduler\n# =========================\ncriterion = nn.CrossEntropyLoss(\n    weight=class_weights,\n    ignore_index=-100\n)\n\noptimizer = AdamW(\n    model.parameters(),\n    lr=5e-5,\n    weight_decay=0.01\n)\n\nnum_epochs = 5\nnum_training_steps = num_epochs * len(train_loader)\nnum_warmup_steps = int(0.1 * num_training_steps)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=num_training_steps\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:16:09.444559Z","iopub.execute_input":"2025-12-30T04:16:09.444886Z","iopub.status.idle":"2025-12-30T04:16:09.758507Z","shell.execute_reply.started":"2025-12-30T04:16:09.444857Z","shell.execute_reply":"2025-12-30T04:16:09.757740Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def decode_bio(label_ids, id2label):\n    \"\"\"\n    Convert BIO label IDs to spans.\n    Returns: [(start, end, technique), ...]\n    \"\"\"\n    spans = []\n    start = None\n    curr_tech = None\n\n    for i, lid in enumerate(label_ids):\n        if lid == -100:\n            continue\n\n        label = id2label[lid]\n\n        if label == \"O\":\n            if start is not None:\n                spans.append((start, i - 1, curr_tech))\n                start = None\n                curr_tech = None\n            continue\n\n        prefix, tech = label.split(\"-\", 1)\n\n        if prefix == \"B\":\n            if start is not None:\n                spans.append((start, i - 1, curr_tech))\n            start = i\n            curr_tech = tech\n\n        elif prefix == \"I\":\n            if start is None:\n                # illegal I → treat as B\n                start = i\n                curr_tech = tech\n            elif tech != curr_tech:\n                spans.append((start, i - 1, curr_tech))\n                start = i\n                curr_tech = tech\n\n    if start is not None:\n        spans.append((start, len(label_ids) - 1, curr_tech))\n\n    return spans","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:17:39.401427Z","iopub.execute_input":"2025-12-30T04:17:39.401808Z","iopub.status.idle":"2025-12-30T04:17:39.408541Z","shell.execute_reply.started":"2025-12-30T04:17:39.401773Z","shell.execute_reply":"2025-12-30T04:17:39.407807Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def span_level_metrics(model, dataloader, id2label):\n    model.eval()\n\n    TP = FP = FN = 0\n\n    with torch.no_grad():\n        for batch in dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n\n            outputs = model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"]\n            )\n\n            preds = outputs.logits.argmax(dim=-1)\n\n            for i in range(preds.size(0)):\n                gold_spans = set(\n                    decode_bio(batch[\"labels\"][i].tolist(), id2label)\n                )\n                pred_spans = set(\n                    decode_bio(preds[i].tolist(), id2label)\n                )\n\n                TP += len(gold_spans & pred_spans)\n                FP += len(pred_spans - gold_spans)\n                FN += len(gold_spans - pred_spans)\n\n    precision = TP / (TP + FP + 1e-8)\n    recall = TP / (TP + FN + 1e-8)\n    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n\n    return {\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n        \"TP\": TP,\n        \"FP\": FP,\n        \"FN\": FN\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:17:46.168969Z","iopub.execute_input":"2025-12-30T04:17:46.169476Z","iopub.status.idle":"2025-12-30T04:17:46.176111Z","shell.execute_reply.started":"2025-12-30T04:17:46.169445Z","shell.execute_reply":"2025-12-30T04:17:46.175306Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from collections import defaultdict\n\ndef technique_metrics(model, dataloader, id2label):\n    model.eval()\n    stats = defaultdict(lambda: {\"TP\": 0, \"FP\": 0, \"FN\": 0})\n\n    with torch.no_grad():\n        for batch in dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"]\n            )\n            preds = outputs.logits.argmax(dim=-1)\n\n            for i in range(preds.size(0)):\n                gold_spans = decode_bio(\n                    batch[\"labels\"][i].tolist(), id2label\n                )\n                pred_spans = decode_bio(\n                    preds[i].tolist(), id2label\n                )\n\n                gold_by_tech = defaultdict(set)\n                pred_by_tech = defaultdict(set)\n\n                for s in gold_spans:\n                    gold_by_tech[s[2]].add(s)\n                for s in pred_spans:\n                    pred_by_tech[s[2]].add(s)\n\n                for tech in set(gold_by_tech) | set(pred_by_tech):\n                    g = gold_by_tech[tech]\n                    p = pred_by_tech[tech]\n                    stats[tech][\"TP\"] += len(g & p)\n                    stats[tech][\"FP\"] += len(p - g)\n                    stats[tech][\"FN\"] += len(g - p)\n\n    results = {}\n    for tech, s in stats.items():\n        P = s[\"TP\"] / (s[\"TP\"] + s[\"FP\"] + 1e-8)\n        R = s[\"TP\"] / (s[\"TP\"] + s[\"FN\"] + 1e-8)\n        F1 = 2 * P * R / (P + R + 1e-8)\n        results[tech] = {\n            \"precision\": P,\n            \"recall\": R,\n            \"f1\": F1,\n            **s\n        }\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:17:49.495158Z","iopub.execute_input":"2025-12-30T04:17:49.495916Z","iopub.status.idle":"2025-12-30T04:17:49.503899Z","shell.execute_reply.started":"2025-12-30T04:17:49.495884Z","shell.execute_reply":"2025-12-30T04:17:49.503150Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# =========================\n# Checkpoint utils\n# =========================\ndef save_checkpoint(epoch, step):\n    torch.save(\n        {\n            \"epoch\": epoch,\n            \"step\": step,\n            \"model\": model.state_dict(),\n            \"optimizer\": optimizer.state_dict(),\n            \"scheduler\": scheduler.state_dict(),\n        },\n        f\"{CHECKPOINT_DIR}/epoch_{epoch}_step_{step}.pt\"\n    )\n\nimport re\n\ndef load_latest_checkpoint():\n    ckpts = []\n\n    for p in Path(CHECKPOINT_DIR).glob(\"epoch_*_step_*.pt\"):\n        m = re.match(r\"epoch_(\\d+)_step_(\\d+)\\.pt\", p.name)\n        if m:\n            epoch = int(m.group(1))\n            step = int(m.group(2))\n            ckpts.append((epoch, step, p))\n\n    if not ckpts:\n        return 0, 0\n\n    # sort by epoch, then step\n    ckpts.sort(key=lambda x: (x[0], x[1]))\n    _, _, ckpt_path = ckpts[-1]\n\n    print(\"Resuming from:\", ckpt_path)\n\n    ckpt = torch.load(ckpt_path, map_location=device)\n    model.load_state_dict(ckpt[\"model\"])\n    optimizer.load_state_dict(ckpt[\"optimizer\"])\n    scheduler.load_state_dict(ckpt[\"scheduler\"])\n\n    return ckpt[\"epoch\"], ckpt[\"step\"] + 1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:17:52.411191Z","iopub.execute_input":"2025-12-30T04:17:52.411579Z","iopub.status.idle":"2025-12-30T04:17:52.420730Z","shell.execute_reply.started":"2025-12-30T04:17:52.411537Z","shell.execute_reply":"2025-12-30T04:17:52.419918Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"O_ID = label2id[\"O\"]\n\n# identify B-* labels\nB_LABEL_IDS = {\n    v for k, v in label2id.items()\n    if k.startswith(\"B-\")\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:17:55.018563Z","iopub.execute_input":"2025-12-30T04:17:55.019310Z","iopub.status.idle":"2025-12-30T04:17:55.022908Z","shell.execute_reply.started":"2025-12-30T04:17:55.019283Z","shell.execute_reply":"2025-12-30T04:17:55.022255Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion):\n    model.eval()\n\n    total_loss = 0.0\n\n    # token counts\n    total_tokens = 0\n    total_correct = 0\n\n    non_o_tokens = 0\n    non_o_correct = 0\n\n    b_tokens = 0\n    b_correct = 0\n\n    b_pred_as_i = 0\n    b_pred_as_o = 0\n\n    with torch.no_grad():\n        for batch in dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n\n            outputs = model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"]\n            )\n\n            logits = outputs.logits\n            labels = batch[\"labels\"]\n\n            loss = criterion(\n                logits.view(-1, logits.size(-1)),\n                labels.view(-1)\n            )\n            total_loss += loss.item()\n\n            preds = logits.argmax(dim=-1)\n\n            mask = labels != -100\n            valid_labels = labels[mask]\n            valid_preds = preds[mask]\n\n            # overall accuracy\n            total_correct += (valid_preds == valid_labels).sum().item()\n            total_tokens += valid_labels.numel()\n\n            # non-O accuracy\n            non_o_mask = valid_labels != O_ID\n            non_o_correct += (\n                valid_preds[non_o_mask] == valid_labels[non_o_mask]\n            ).sum().item()\n            non_o_tokens += non_o_mask.sum().item()\n\n            # B-only accuracy\n            b_mask = torch.isin(valid_labels, torch.tensor(\n                list(B_LABEL_IDS), device=device\n            ))\n\n            b_correct += (\n                valid_preds[b_mask] == valid_labels[b_mask]\n            ).sum().item()\n            b_tokens += b_mask.sum().item()\n\n            # B confusion\n            b_pred_as_i += (\n                torch.isin(valid_labels, torch.tensor(list(B_LABEL_IDS), device=device)) &\n                torch.isin(valid_preds, torch.tensor(\n                    [v for k, v in label2id.items() if k.startswith(\"I-\")],\n                    device=device\n                ))\n            ).sum().item()\n\n            b_pred_as_o += (\n                (valid_labels != O_ID) &\n                torch.isin(valid_labels, torch.tensor(list(B_LABEL_IDS), device=device)) &\n                (valid_preds == O_ID)\n            ).sum().item()\n\n    return {\n        \"val_loss\": total_loss / len(dataloader),\n        \"acc_all\": total_correct / total_tokens,\n        \"acc_non_o\": non_o_correct / max(1, non_o_tokens),\n        \"acc_b\": b_correct / max(1, b_tokens),\n        \"b_as_i\": b_pred_as_i,\n        \"b_as_o\": b_pred_as_o,\n        \"b_total\": b_tokens,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:17:58.056795Z","iopub.execute_input":"2025-12-30T04:17:58.057442Z","iopub.status.idle":"2025-12-30T04:17:58.071465Z","shell.execute_reply.started":"2025-12-30T04:17:58.057413Z","shell.execute_reply":"2025-12-30T04:17:58.070738Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# =========================\n# Resume if possible\n# =========================\nstart_epoch, start_step = load_latest_checkpoint()\n\n# =========================\n# Metric history (Day 4)\n# =========================\ntrain_losses = []\nval_losses = []\nacc_all_hist = []\nacc_non_o_hist = []\nacc_b_hist = []\n\n# =========================\n# Day 5 metrics dir\n# =========================\nMETRICS_DIR = \"/kaggle/working/metrics\"\nPath(METRICS_DIR).mkdir(exist_ok=True)\n\n# =========================\n# Training Loop\n# =========================\nglobal_step = start_step\n\nfor epoch in range(start_epoch, num_epochs):\n    model.train()\n    epoch_loss = 0.0\n    print(f\"\\nEpoch {epoch}\")\n\n    for step, batch in enumerate(train_loader):\n        if epoch == start_epoch and step < start_step:\n            continue\n\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        optimizer.zero_grad()\n\n        outputs = model(\n            input_ids=batch[\"input_ids\"],\n            attention_mask=batch[\"attention_mask\"]\n        )\n\n        loss = criterion(\n            outputs.logits.view(-1, outputs.logits.size(-1)),\n            batch[\"labels\"].view(-1)\n        )\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        optimizer.step()\n        scheduler.step()\n\n        epoch_loss += loss.item()\n\n        if global_step % 200 == 0:\n            print(f\"step {global_step} | loss {loss.item():.4f}\")\n\n        if global_step % 1000 == 0:\n            save_checkpoint(epoch, global_step)\n\n        global_step += 1\n\n    # =========================\n    # End of epoch — Day 4 eval\n    # =========================\n    avg_train_loss = epoch_loss / len(train_loader)\n\n    metrics = evaluate(model, val_loader, criterion)\n\n    train_losses.append(avg_train_loss)\n    val_losses.append(metrics[\"val_loss\"])\n    acc_all_hist.append(metrics[\"acc_all\"])\n    acc_non_o_hist.append(metrics[\"acc_non_o\"])\n    acc_b_hist.append(metrics[\"acc_b\"])\n\n    print(\n        f\"Epoch {epoch} | \"\n        f\"train {avg_train_loss:.4f} | \"\n        f\"val {metrics['val_loss']:.4f} | \"\n        f\"acc {metrics['acc_all']:.4f} | \"\n        f\"non-O {metrics['acc_non_o']:.4f} | \"\n        f\"B {metrics['acc_b']:.4f}\"\n    )\n\n    print(\n        f\"    B confusion: \"\n        f\"B→I {metrics['b_as_i']} | \"\n        f\"B→O {metrics['b_as_o']} / {metrics['b_total']}\"\n    )\n\n    # =========================\n    # Day 5 — Span-level metrics\n    # =========================\n    span_metrics = span_level_metrics(model, val_loader, id2label)\n    tech_metrics = technique_metrics(model, val_loader, id2label)\n\n    print(\n        f\"[Span] \"\n        f\"P {span_metrics['precision']:.3f} | \"\n        f\"R {span_metrics['recall']:.3f} | \"\n        f\"F1 {span_metrics['f1']:.3f}\"\n    )\n\n    # =========================\n    # Save metrics (Day 5)\n    # =========================\n    with open(f\"{METRICS_DIR}/epoch_{epoch}.json\", \"w\") as f:\n        json.dump(\n            {\n                \"epoch\": epoch,\n                \"train_loss\": avg_train_loss,\n                \"val_loss\": metrics[\"val_loss\"],\n                \"token_metrics\": {\n                    \"acc_all\": metrics[\"acc_all\"],\n                    \"acc_non_o\": metrics[\"acc_non_o\"],\n                    \"acc_b\": metrics[\"acc_b\"],\n                    \"b_as_i\": metrics[\"b_as_i\"],\n                    \"b_as_o\": metrics[\"b_as_o\"],\n                    \"b_total\": metrics[\"b_total\"],\n                },\n                \"span_metrics\": span_metrics,\n                \"technique_metrics\": tech_metrics,\n            },\n            f,\n            indent=2\n        )\n\n    save_checkpoint(epoch, global_step)\n\nprint(\"✅ Training + Day 5 evaluation complete\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T04:18:34.238178Z","iopub.execute_input":"2025-12-30T04:18:34.238516Z","iopub.status.idle":"2025-12-30T04:19:31.027401Z","shell.execute_reply.started":"2025-12-30T04:18:34.238456Z","shell.execute_reply":"2025-12-30T04:19:31.026666Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 0\nstep 0 | loss 1.3875\nEpoch 0 | train 1.5619 | val 2.3032 | acc 0.8148 | non-O 0.1381 | B 0.0420\n    B confusion: B→I 70 | B→O 135 / 238\n[Span] P 0.016 | R 0.052 | F1 0.024\n\nEpoch 1\nEpoch 1 | train 1.5863 | val 2.3032 | acc 0.8148 | non-O 0.1381 | B 0.0420\n    B confusion: B→I 70 | B→O 135 / 238\n[Span] P 0.016 | R 0.052 | F1 0.024\n\nEpoch 2\nEpoch 2 | train 1.5900 | val 2.3032 | acc 0.8148 | non-O 0.1381 | B 0.0420\n    B confusion: B→I 70 | B→O 135 / 238\n[Span] P 0.016 | R 0.052 | F1 0.024\n\nEpoch 3\nEpoch 3 | train 1.5774 | val 2.3032 | acc 0.8148 | non-O 0.1381 | B 0.0420\n    B confusion: B→I 70 | B→O 135 / 238\n[Span] P 0.016 | R 0.052 | F1 0.024\n\nEpoch 4\nstep 200 | loss 1.8423\nEpoch 4 | train 1.5798 | val 2.3032 | acc 0.8148 | non-O 0.1381 | B 0.0420\n    B confusion: B→I 70 | B→O 135 / 238\n[Span] P 0.016 | R 0.052 | F1 0.024\n✅ Training + Day 5 evaluation complete\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"def render_spans(text, spans, tag):\n    \"\"\"\n    spans: List[(char_start, char_end, technique)]\n    tag: 'GOLD' or 'PRED'\n    \"\"\"\n    spans = sorted(spans, key=lambda x: x[0])\n    rendered = \"\"\n    last = 0\n\n    for start, end, tech in spans:\n        rendered += text[last:start]\n        rendered += f\"[{tag}|{tech}]\" + text[start:end] + f\"[/{tag}]\"\n        last = end\n\n    rendered += text[last:]\n    return rendered","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T14:49:53.523310Z","iopub.execute_input":"2026-01-29T14:49:53.523992Z","iopub.status.idle":"2026-01-29T14:49:53.528993Z","shell.execute_reply.started":"2026-01-29T14:49:53.523960Z","shell.execute_reply":"2026-01-29T14:49:53.528157Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def token_span_to_char(span, offsets):\n    \"\"\"\n    span: (start_token, end_token, technique)\n    offsets: tokenizer offset_mapping\n    \"\"\"\n    start_tok, end_tok, tech = span\n\n    char_start = offsets[start_tok][0]\n    char_end = offsets[end_tok][1]\n\n    return (char_start, char_end, tech)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T14:49:56.001722Z","iopub.execute_input":"2026-01-29T14:49:56.002008Z","iopub.status.idle":"2026-01-29T14:49:56.006188Z","shell.execute_reply.started":"2026-01-29T14:49:56.001983Z","shell.execute_reply":"2026-01-29T14:49:56.005555Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def visualize_sample(text, offsets, gold_spans, pred_spans):\n    gold_char_spans = [\n        token_span_to_char(s, offsets) for s in gold_spans\n    ]\n    pred_char_spans = [\n        token_span_to_char(s, offsets) for s in pred_spans\n    ]\n\n    gold_view = render_spans(text, gold_char_spans, \"GOLD\")\n    pred_view = render_spans(text, pred_char_spans, \"PRED\")\n\n    print(\"\\n===== GOLD =====\\n\")\n    print(gold_view)\n    print(\"\\n===== PRED =====\\n\")\n    print(pred_view)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T14:49:56.306174Z","iopub.execute_input":"2026-01-29T14:49:56.306793Z","iopub.status.idle":"2026-01-29T14:49:56.311680Z","shell.execute_reply.started":"2026-01-29T14:49:56.306763Z","shell.execute_reply":"2026-01-29T14:49:56.310917Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"failure_cases = []\n\nwith torch.no_grad():\n    for batch in val_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(\n            input_ids=batch[\"input_ids\"],\n            attention_mask=batch[\"attention_mask\"]\n        )\n        preds = outputs.logits.argmax(dim=-1)\n\n        for i in range(preds.size(0)):\n            gold_spans = decode_bio(\n                batch[\"labels\"][i].tolist(), id2label\n            )\n            pred_spans = decode_bio(\n                preds[i].tolist(), id2label\n            )\n\n            if set(gold_spans) != set(pred_spans):\n                print(\"FOUND FAILURE\")\n                print(\"Gold:\", gold_spans)\n                print(\"Pred:\", pred_spans)\n\n                failure_cases.append({\n                    \"gold\": gold_spans,\n                    \"pred\": pred_spans,\n                    \"input_ids\": batch[\"input_ids\"][i],\n                })\n                break\n\n        if failure_cases:\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T14:52:19.520518Z","iopub.execute_input":"2026-01-29T14:52:19.521303Z","iopub.status.idle":"2026-01-29T14:52:19.594866Z","shell.execute_reply.started":"2026-01-29T14:52:19.521271Z","shell.execute_reply":"2026-01-29T14:52:19.594293Z"}},"outputs":[{"name":"stdout","text":"FOUND FAILURE\nGold: [(63, 84, 'Appeal_to_fear-prejudice'), (114, 126, 'Loaded_Language'), (130, 142, 'Loaded_Language'), (167, 168, 'Loaded_Language'), (225, 232, 'Loaded_Language'), (402, 412, 'Doubt'), (413, 428, 'Doubt')]\nPred: [(62, 68, 'Appeal_to_fear-prejudice'), (69, 71, 'Black-and-White_Fallacy'), (72, 72, 'Appeal_to_fear-prejudice'), (73, 74, 'Black-and-White_Fallacy'), (75, 79, 'Appeal_to_fear-prejudice'), (80, 80, 'Black-and-White_Fallacy'), (81, 81, 'Appeal_to_fear-prejudice'), (113, 113, 'Exaggeration,Minimisation'), (114, 117, 'Name_Calling,Labeling'), (118, 119, 'Exaggeration,Minimisation'), (120, 121, 'Loaded_Language'), (122, 124, 'Loaded_Language'), (125, 126, 'Exaggeration,Minimisation'), (130, 130, 'Causal_Oversimplification'), (131, 134, 'Slogans'), (135, 135, 'Flag-Waving'), (136, 136, 'Slogans'), (137, 137, 'Flag-Waving'), (138, 138, 'Causal_Oversimplification'), (139, 139, 'Slogans'), (140, 140, 'Causal_Oversimplification'), (141, 141, 'Flag-Waving'), (142, 142, 'Slogans'), (155, 156, 'Loaded_Language'), (167, 167, 'Loaded_Language'), (168, 168, 'Loaded_Language'), (171, 173, 'Causal_Oversimplification'), (226, 227, 'Name_Calling,Labeling'), (276, 276, 'Name_Calling,Labeling'), (386, 388, 'Loaded_Language'), (390, 390, 'Loaded_Language'), (392, 392, 'Loaded_Language'), (394, 398, 'Loaded_Language'), (399, 399, 'Doubt'), (400, 400, 'Loaded_Language'), (401, 412, 'Doubt'), (413, 413, 'Thought-terminating_Cliches'), (414, 416, 'Doubt'), (417, 425, 'Doubt'), (426, 426, 'Black-and-White_Fallacy'), (427, 427, 'Appeal_to_fear-prejudice'), (428, 428, 'Doubt'), (430, 432, 'Name_Calling,Labeling'), (442, 443, 'Doubt'), (445, 445, 'Doubt'), (447, 448, 'Doubt'), (449, 449, 'Causal_Oversimplification'), (450, 451, 'Doubt'), (453, 455, 'Doubt')]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"ex = failure_cases[0]\nprint(\"Gold spans:\", ex[\"gold\"])\nprint(\"Pred spans:\", ex[\"pred\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T14:52:50.038210Z","iopub.execute_input":"2026-01-29T14:52:50.039020Z","iopub.status.idle":"2026-01-29T14:52:50.045932Z","shell.execute_reply.started":"2026-01-29T14:52:50.038970Z","shell.execute_reply":"2026-01-29T14:52:50.045022Z"}},"outputs":[{"name":"stdout","text":"Gold spans: [(63, 84, 'Appeal_to_fear-prejudice'), (114, 126, 'Loaded_Language'), (130, 142, 'Loaded_Language'), (167, 168, 'Loaded_Language'), (225, 232, 'Loaded_Language'), (402, 412, 'Doubt'), (413, 428, 'Doubt')]\nPred spans: [(62, 68, 'Appeal_to_fear-prejudice'), (69, 71, 'Black-and-White_Fallacy'), (72, 72, 'Appeal_to_fear-prejudice'), (73, 74, 'Black-and-White_Fallacy'), (75, 79, 'Appeal_to_fear-prejudice'), (80, 80, 'Black-and-White_Fallacy'), (81, 81, 'Appeal_to_fear-prejudice'), (113, 113, 'Exaggeration,Minimisation'), (114, 117, 'Name_Calling,Labeling'), (118, 119, 'Exaggeration,Minimisation'), (120, 121, 'Loaded_Language'), (122, 124, 'Loaded_Language'), (125, 126, 'Exaggeration,Minimisation'), (130, 130, 'Causal_Oversimplification'), (131, 134, 'Slogans'), (135, 135, 'Flag-Waving'), (136, 136, 'Slogans'), (137, 137, 'Flag-Waving'), (138, 138, 'Causal_Oversimplification'), (139, 139, 'Slogans'), (140, 140, 'Causal_Oversimplification'), (141, 141, 'Flag-Waving'), (142, 142, 'Slogans'), (155, 156, 'Loaded_Language'), (167, 167, 'Loaded_Language'), (168, 168, 'Loaded_Language'), (171, 173, 'Causal_Oversimplification'), (226, 227, 'Name_Calling,Labeling'), (276, 276, 'Name_Calling,Labeling'), (386, 388, 'Loaded_Language'), (390, 390, 'Loaded_Language'), (392, 392, 'Loaded_Language'), (394, 398, 'Loaded_Language'), (399, 399, 'Doubt'), (400, 400, 'Loaded_Language'), (401, 412, 'Doubt'), (413, 413, 'Thought-terminating_Cliches'), (414, 416, 'Doubt'), (417, 425, 'Doubt'), (426, 426, 'Black-and-White_Fallacy'), (427, 427, 'Appeal_to_fear-prejudice'), (428, 428, 'Doubt'), (430, 432, 'Name_Calling,Labeling'), (442, 443, 'Doubt'), (445, 445, 'Doubt'), (447, 448, 'Doubt'), (449, 449, 'Causal_Oversimplification'), (450, 451, 'Doubt'), (453, 455, 'Doubt')]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\n\nfor f in os.listdir(\"/kaggle/working/checkpoints\"):\n    print(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:00:28.446487Z","iopub.execute_input":"2026-01-29T15:00:28.447306Z","iopub.status.idle":"2026-01-29T15:00:28.451666Z","shell.execute_reply.started":"2026-01-29T15:00:28.447273Z","shell.execute_reply":"2026-01-29T15:00:28.450981Z"}},"outputs":[{"name":"stdout","text":"epoch_2_step_123.pt\nepoch_0_step_41.pt\nepoch_4_step_205.pt\nepoch_0_step_0.pt\nepoch_3_step_164.pt\nepoch_1_step_82.pt\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import torch\n\nckpt_path = \"/kaggle/working/checkpoints/epoch_4_step_205.pt\"\n\nckpt = torch.load(ckpt_path, map_location=\"cpu\")\n\nprint(ckpt.keys())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:02:01.499865Z","iopub.execute_input":"2026-01-29T15:02:01.500536Z","iopub.status.idle":"2026-01-29T15:02:01.866183Z","shell.execute_reply.started":"2026-01-29T15:02:01.500507Z","shell.execute_reply":"2026-01-29T15:02:01.865574Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['epoch', 'step', 'model', 'optimizer', 'scheduler'])\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"MODEL_EXPORT_DIR = \"/kaggle/working/export\"\nos.makedirs(MODEL_EXPORT_DIR, exist_ok=True)\n\ntorch.save(\n    {\n        \"model_state_dict\": ckpt[\"model\"],\n        \"label2id\": label2id,\n        \"id2label\": id2label,\n        \"num_labels\": num_labels,\n        \"base_model\": \"distilbert-base-uncased\",\n        \"notes\": \"MindLens Span Detector v1.0 — boundary-fragmentation baseline\"\n    },\n    f\"{MODEL_EXPORT_DIR}/span_detector_v1.pt\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:02:20.235498Z","iopub.execute_input":"2026-01-29T15:02:20.236238Z","iopub.status.idle":"2026-01-29T15:02:20.460367Z","shell.execute_reply.started":"2026-01-29T15:02:20.236193Z","shell.execute_reply":"2026-01-29T15:02:20.459715Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}